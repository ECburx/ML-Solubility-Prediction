{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AlphaNN\n",
    "\n",
    "We studied the success of AlphaFold 2 and attempted to incorporate its architectural design into our previously described model ingeniously. AlphaFold 2 incorporates neural network architectures and training procedures that are guided by the evolutionary, physical, and geometric constraints of protein structures.\n",
    "\n",
    "We chose to integrate GAT and GCN layers as the attention-based and non-attention-based components, respectively, in our subnetwork called AlphaNN. The aim is to take advantage of the respective strengths of both models. Specifically, GAT layers are proficient in modeling the node-to-node relationships in the graph, while GCN layers are well-suited for capturing the global graph structure.\n",
    "\n",
    "Another notable technique utilized in their model involves reinforcing the concept of iterative refinement, termed recycling, which could be integrated into our solubility prediction model, such as AlphaNN and 1D-CNN."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from data.dataset import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from data.featurization.dgl_Graph import DGL_Graph\n",
    "from model.abstractmodel import AbstractModel\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "TRN = Dataset.load_csv(\"ds/all/TRN_DC\")\n",
    "TST1 = Dataset.load_csv(\"ds/all/TST_1\")\n",
    "TST2 = Dataset.load_csv(\"ds/all/TST_2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "featurizer = DGL_Graph(\n",
    "    graph_type=\"BI_GRAPH\",\n",
    "    featurize_type=\"Canonical\",\n",
    "    self_loop=True\n",
    ")\n",
    "TRN.X = TRN.featurize(featurizer)\n",
    "TST1.X = TST1.featurize(featurizer)\n",
    "TST2.X = TST2.featurize(featurizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from model.alpha.AlphaGNN import AlphaGNN\n",
    "\n",
    "AbstractModel.set_seed(2387)\n",
    "num_heads = 5\n",
    "MODEL = AlphaGNN(\n",
    "    task_type=\"regression\",\n",
    "    # AlphaGNN Configuration\n",
    "    n_tasks=1,\n",
    "    in_feats=featurizer.get_node_feat_size(),\n",
    "    recycle=3,\n",
    "    # hidden_feats=[64, 64 * num_heads],\n",
    "    allow_zero_in_degree=False,\n",
    "    gat_num_heads=num_heads,\n",
    "    gat_feat_drop=0.,\n",
    "    gat_attn_drop=0.,\n",
    "    gat_alpha=0,\n",
    "    gat_residual=True,\n",
    "    gat_agg_mode=\"flatten\",\n",
    "    gat_bias=True,\n",
    "    gcn_norm=\"both\",\n",
    "    gcn_residual=True,\n",
    "    gcn_batchnorm=False,\n",
    "    gcn_dropout=0.13108904159657686,\n",
    "    recycle_alpha=0.7,\n",
    "    predictor_hidden_feats=128,\n",
    "    predictor_dropout=0.,\n",
    "    # Abstract DGL Configuration\n",
    "    lr=0.001,\n",
    "    y_name=\"LogS exp (mol/L)\",\n",
    "    weight_decay=0.007319939418114051,\n",
    "    batch_size=4096,\n",
    ")\n",
    "scores = MODEL.fit(TRN, val=TST1, epochs=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"loss\": [v.item() for v in MODEL.scores[\"loss\"]],\n",
    "    \"rmse\": [v.item() for v in MODEL.scores[\"rmse\"]]\n",
    "}).plot()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "trn_sets, val_sets = TRN.k_fold_split(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Expect to use 'DGL_Graph' to featurize SMILES\n",
      "[INFO] Device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 338/800 [02:10<02:58,  2.59it/s, loss: 2.345 rmse: 1.499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Expect to use 'DGL_Graph' to featurize SMILES\n",
      "[INFO] Device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 336/800 [02:09<02:58,  2.60it/s, loss: 1.828 rmse: 1.863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Expect to use 'DGL_Graph' to featurize SMILES\n",
      "[INFO] Device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 323/800 [02:04<03:03,  2.60it/s, loss: 1.989 rmse: 1.868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Expect to use 'DGL_Graph' to featurize SMILES\n",
      "[INFO] Device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 349/800 [02:38<03:25,  2.20it/s, loss: 2.091 rmse: 1.201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Expect to use 'DGL_Graph' to featurize SMILES\n",
      "[INFO] Device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 334/800 [02:18<03:12,  2.42it/s, loss: 2.102 rmse: 1.313]\n"
     ]
    }
   ],
   "source": [
    "from model.alpha.AlphaGNN import AlphaGNN\n",
    "\n",
    "AbstractModel.set_seed(2387)\n",
    "num_heads = 4\n",
    "\n",
    "k_pred_tst1 = []\n",
    "k_pred_tst2 = []\n",
    "\n",
    "for trn, val in zip(trn_sets, val_sets):\n",
    "    model = AlphaGNN(\n",
    "        task_type=\"regression\",\n",
    "        # AlphaGNN Configuration\n",
    "        n_tasks=1,\n",
    "        in_feats=featurizer.get_node_feat_size(),\n",
    "        recycle=3,\n",
    "        # hidden_feats=[64, 64 * num_heads],\n",
    "        allow_zero_in_degree=False,\n",
    "        gat_num_heads=num_heads,\n",
    "        gat_feat_drop=0.,\n",
    "        gat_attn_drop=0.,\n",
    "        gat_alpha=0,\n",
    "        gat_residual=True,\n",
    "        gat_agg_mode=\"flatten\",\n",
    "        gat_bias=True,\n",
    "        gcn_norm=\"both\",\n",
    "        gcn_residual=True,\n",
    "        gcn_batchnorm=False,\n",
    "        gcn_dropout=0.13108904159657686,\n",
    "        recycle_alpha=0.7,\n",
    "        predictor_hidden_feats=128,\n",
    "        predictor_dropout=0.,\n",
    "        # Abstract DGL Configuration\n",
    "        lr=0.001,\n",
    "        y_name=\"LogS exp (mol/L)\",\n",
    "        weight_decay=0.007319939418114051,\n",
    "        batch_size=4096,\n",
    "    )\n",
    "    model.fit(trn, val=val, epochs=800, min_epoch=300, early_stop=20)\n",
    "\n",
    "    k_pred_tst1.append(model.predict(TST1).cpu())\n",
    "    k_pred_tst2.append(model.predict(TST2).cpu())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "pred_tst1 = [torch.mean(pred_i).item() for pred_i in torch.cat(k_pred_tst1, 1)]\n",
    "pred_tst2 = [torch.mean(pred_i).item() for pred_i in torch.cat(k_pred_tst2, 1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TST1 : RMSE 0.9859856373465161\n",
      "TST2 : RMSE 1.7583186905921087\n"
     ]
    }
   ],
   "source": [
    "print(f\"TST1 : RMSE {mean_squared_error(TST1.y, pred_tst1, squared=False)}\")\n",
    "print(f\"TST2 : RMSE {mean_squared_error(TST2.y, pred_tst2, squared=False)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TST1 : R^2 0.3933251547531803\n",
      "TST2 : R^2 0.3259840971371806\n"
     ]
    }
   ],
   "source": [
    "print(f\"TST1 : R^2 {r2_score(TST1.y, pred_tst1)}\")\n",
    "print(f\"TST2 : R^2 {r2_score(TST2.y, pred_tst2)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
